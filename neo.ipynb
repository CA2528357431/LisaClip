{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.styler import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lr1 = 0.001\n",
    "lr2 = 0.0003\n",
    "# lr_fast = 0.0002\n",
    "# lr_slow = 0.00005\n",
    "\n",
    "# model = Unet(device).to(device)\n",
    "model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "for x in vgg.parameters():\n",
    "    x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 150\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "file_u = open(\"neo.txt\", \"r\")\n",
    "loss_li = file_u.readline()\n",
    "# loss_li = [float(x) for x in loss_li.split()]\n",
    "loss_li = None\n",
    "if not loss_li:\n",
    "    loss_li = [0]*100\n",
    "\n",
    "cur_times = int(file_u.readline())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 50) == 0:\n",
    "        #     pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n",
    "\n",
    "    # torch.save(model,'unet.pth')\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_fast = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_slow = optim.Adam(model.parameters(), lr=lr_fast)\n",
    "    # opt_loss = optim.Adam(cliploss.parameters(), lr=lr_slow)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # opt_slow.zero_grad()\n",
    "        # opt_fast.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        # gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "        patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.forward_prior(pic, source, neo_pic, target)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "\n",
    "        # patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        # patch_loss_fast.backward(retain_graph=True)\n",
    "        # patch_loss_slow.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        loss_li[i]+=(loss.item())\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            neo_pic = model(input)\n",
    "            pil = topil(neo_pic.squeeze(0).cpu())\n",
    "            pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "            pil.save(f\"mid.jpg\")\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic2/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16440\\683721222.py:3: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
      "E:\\Anaconda\\envs\\sth\\lib\\site-packages\\torchvision\\transforms\\transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pil = Image.open(f\"./source_pic/emma man.jpg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False\n",
    "\n",
    "source = \"photo\"\n",
    "# source = \"white shirt\"\n",
    "# source = \"man\"\n",
    "# source = \"anime\"\n",
    "\n",
    "# target = \"Neon light\"\n",
    "# target = \"metal\"\n",
    "# target = \"Van gogh\"\n",
    "# target = \"Japanese anime\"\n",
    "# target = \"woman\"\n",
    "target = \"snowy\"\n",
    "# target = \"white wool\"\n",
    "# target = \"black suit\"\n",
    "# target = \"sketch\"\n",
    "# target = \"pop art of night city\"\n",
    "# target = \"starry night by Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Chinese Ink and wash painting\"\n",
    "# target = \"The great wave off kanagawa by Hokusai\"\n",
    "\n",
    "path = \"result/result12.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.06487759947776794\n",
      "iter: 2 loss: 0.06040358543395996\n",
      "iter: 3 loss: 0.03927142173051834\n",
      "iter: 4 loss: 0.027946343645453453\n",
      "iter: 5 loss: 0.020156491547822952\n",
      "iter: 6 loss: 0.013150975108146667\n",
      "iter: 7 loss: 0.008388716727495193\n",
      "iter: 8 loss: 0.005981182213872671\n",
      "iter: 9 loss: 0.004255324602127075\n",
      "iter: 10 loss: 0.003868627827614546\n",
      "iter: 11 loss: 0.0034963577054440975\n",
      "iter: 12 loss: 0.0032865942921489477\n",
      "iter: 13 loss: 0.0030545229092240334\n",
      "iter: 14 loss: 0.002709121908992529\n",
      "iter: 15 loss: 0.0024101953022181988\n",
      "iter: 16 loss: 0.002179228700697422\n",
      "iter: 17 loss: 0.001995484810322523\n",
      "iter: 18 loss: 0.0018243843223899603\n",
      "iter: 19 loss: 0.0016827614745125175\n",
      "iter: 20 loss: 0.0015952258836477995\n",
      "iter: 21 loss: 0.001503292005509138\n",
      "iter: 22 loss: 0.0013940322678536177\n",
      "iter: 23 loss: 0.0013015121221542358\n",
      "iter: 24 loss: 0.0012250059517100453\n",
      "iter: 25 loss: 0.0011668835068121552\n",
      "iter: 26 loss: 0.0011299209436401725\n",
      "iter: 27 loss: 0.001105481176637113\n",
      "iter: 28 loss: 0.0010820315219461918\n",
      "iter: 29 loss: 0.0010525966063141823\n",
      "iter: 30 loss: 0.0010169502347707748\n",
      "iter: 31 loss: 0.0009789182804524899\n",
      "iter: 32 loss: 0.0009417133405804634\n",
      "iter: 33 loss: 0.000906208879314363\n",
      "iter: 34 loss: 0.0008729792898520827\n",
      "iter: 35 loss: 0.0008438650984317064\n",
      "iter: 36 loss: 0.0008201942546293139\n",
      "iter: 37 loss: 0.0008011729223653674\n",
      "iter: 38 loss: 0.0007843055645935237\n",
      "iter: 39 loss: 0.0007675637025386095\n",
      "iter: 40 loss: 0.0007500338251702487\n",
      "iter: 41 loss: 0.0007315985858440399\n",
      "iter: 42 loss: 0.0007127559510990977\n",
      "iter: 43 loss: 0.0006941810133866966\n",
      "iter: 44 loss: 0.0006766795413568616\n",
      "iter: 45 loss: 0.0006607958930544555\n",
      "iter: 46 loss: 0.0006461451994255185\n",
      "iter: 47 loss: 0.0006323895649984479\n",
      "iter: 48 loss: 0.0006197275943122804\n",
      "iter: 49 loss: 0.0006082835607230663\n",
      "iter: 50 loss: 0.0005976890097372234\n",
      "iter: 51 loss: 0.0005870948079973459\n",
      "iter: 52 loss: 0.0005767454858869314\n",
      "iter: 53 loss: 0.0005672863335348666\n",
      "iter: 54 loss: 0.0005583384190686047\n",
      "iter: 55 loss: 0.0005497464444488287\n",
      "iter: 56 loss: 0.0005417934153228998\n",
      "iter: 57 loss: 0.000534042832441628\n",
      "iter: 58 loss: 0.0005259783356450498\n",
      "iter: 59 loss: 0.0005178794963285327\n",
      "iter: 60 loss: 0.0005104568554088473\n",
      "iter: 61 loss: 0.0005040154792368412\n",
      "iter: 62 loss: 0.0004979277728125453\n",
      "iter: 63 loss: 0.0004916602047160268\n",
      "iter: 64 loss: 0.0004852201964240521\n",
      "iter: 65 loss: 0.00047858693869784474\n",
      "iter: 66 loss: 0.00047207780880853534\n",
      "iter: 67 loss: 0.00046592994476668537\n",
      "iter: 68 loss: 0.0004599576350301504\n",
      "iter: 69 loss: 0.00045405919081531465\n",
      "iter: 70 loss: 0.0004482936055865139\n",
      "iter: 71 loss: 0.0004428821848705411\n",
      "iter: 72 loss: 0.00043776127859018743\n",
      "iter: 73 loss: 0.00043270894093438983\n",
      "iter: 74 loss: 0.0004277168191038072\n",
      "iter: 75 loss: 0.0004227211175020784\n",
      "iter: 76 loss: 0.0004177877854090184\n",
      "iter: 77 loss: 0.0004130168817937374\n",
      "iter: 78 loss: 0.00040839146822690964\n",
      "iter: 79 loss: 0.0004037999315187335\n",
      "iter: 80 loss: 0.0003991718403995037\n",
      "iter: 81 loss: 0.0003946184879168868\n",
      "iter: 82 loss: 0.00039017689414322376\n",
      "iter: 83 loss: 0.00038583786226809025\n",
      "iter: 84 loss: 0.0003815771488007158\n",
      "iter: 85 loss: 0.0003773375356104225\n",
      "iter: 86 loss: 0.00037312228232622147\n",
      "iter: 87 loss: 0.0003689704171847552\n",
      "iter: 88 loss: 0.00036490088677965105\n",
      "iter: 89 loss: 0.0003608746628742665\n",
      "iter: 90 loss: 0.000356893811840564\n",
      "iter: 91 loss: 0.0003530150279402733\n",
      "iter: 92 loss: 0.000349249632563442\n",
      "iter: 93 loss: 0.00034560466883704066\n",
      "iter: 94 loss: 0.0003420493449084461\n",
      "iter: 95 loss: 0.0003385687596164644\n",
      "iter: 96 loss: 0.0003351455961819738\n",
      "iter: 97 loss: 0.00033178459852933884\n",
      "iter: 98 loss: 0.0003284927224740386\n",
      "iter: 99 loss: 0.0003252600145060569\n",
      "iter: 100 loss: 0.00032208231277763844\n",
      "iter: 1 loss: 9718.1015625\n",
      "iter: 2 loss: 9499.654296875\n",
      "iter: 3 loss: 9359.1240234375\n",
      "iter: 4 loss: 9328.564453125\n",
      "iter: 5 loss: 9220.6083984375\n",
      "iter: 6 loss: 9214.3525390625\n",
      "iter: 7 loss: 9033.71484375\n",
      "iter: 8 loss: 8996.48828125\n",
      "iter: 9 loss: 9032.0146484375\n",
      "iter: 10 loss: 9033.8369140625\n",
      "iter: 11 loss: 8958.0615234375\n",
      "iter: 12 loss: 8926.8671875\n",
      "iter: 13 loss: 8769.1015625\n",
      "iter: 14 loss: 8775.9296875\n",
      "iter: 15 loss: 8680.0166015625\n",
      "iter: 16 loss: 8648.7509765625\n",
      "iter: 17 loss: 8627.9697265625\n",
      "iter: 18 loss: 8675.1083984375\n",
      "iter: 19 loss: 8581.6416015625\n",
      "iter: 20 loss: 8588.791015625\n",
      "iter: 21 loss: 8478.904296875\n",
      "iter: 22 loss: 8547.2333984375\n",
      "iter: 23 loss: 8551.69140625\n",
      "iter: 24 loss: 8507.1337890625\n",
      "iter: 25 loss: 8449.37890625\n",
      "iter: 26 loss: 8284.763671875\n",
      "iter: 27 loss: 8291.037109375\n",
      "iter: 28 loss: 8186.1171875\n",
      "iter: 29 loss: 8119.39111328125\n",
      "iter: 30 loss: 8100.47021484375\n",
      "iter: 31 loss: 8027.73779296875\n",
      "iter: 32 loss: 8110.591796875\n",
      "iter: 33 loss: 8073.11083984375\n",
      "iter: 34 loss: 8022.32080078125\n",
      "iter: 35 loss: 8032.7646484375\n",
      "iter: 36 loss: 7886.66162109375\n",
      "iter: 37 loss: 7869.23095703125\n",
      "iter: 38 loss: 7948.7587890625\n",
      "iter: 39 loss: 7823.71044921875\n",
      "iter: 40 loss: 7922.76953125\n",
      "iter: 41 loss: 7944.5107421875\n",
      "iter: 42 loss: 7862.0341796875\n",
      "iter: 43 loss: 7864.8076171875\n",
      "iter: 44 loss: 7796.55224609375\n",
      "iter: 45 loss: 7747.54443359375\n",
      "iter: 46 loss: 7866.36669921875\n",
      "iter: 47 loss: 7564.22802734375\n",
      "iter: 48 loss: 7717.06591796875\n",
      "iter: 49 loss: 7625.8896484375\n",
      "iter: 50 loss: 7448.56884765625\n",
      "iter: 51 loss: 7569.94287109375\n",
      "iter: 52 loss: 7573.939453125\n",
      "iter: 53 loss: 7674.005859375\n",
      "iter: 54 loss: 7386.2119140625\n",
      "iter: 55 loss: 7570.248046875\n",
      "iter: 56 loss: 7366.68408203125\n",
      "iter: 57 loss: 7544.6025390625\n",
      "iter: 58 loss: 7310.60107421875\n",
      "iter: 59 loss: 7018.96044921875\n",
      "iter: 60 loss: 7222.130859375\n",
      "iter: 61 loss: 7071.1025390625\n",
      "iter: 62 loss: 7063.46826171875\n",
      "iter: 63 loss: 6969.83203125\n",
      "iter: 64 loss: 6386.44921875\n",
      "iter: 65 loss: 7063.51806640625\n",
      "iter: 66 loss: 6918.5771484375\n",
      "iter: 67 loss: 7124.9716796875\n",
      "iter: 68 loss: 6151.11279296875\n",
      "iter: 69 loss: 6956.68359375\n",
      "iter: 70 loss: 6088.43212890625\n",
      "iter: 71 loss: 6359.26513671875\n",
      "iter: 72 loss: 6707.498046875\n",
      "iter: 73 loss: 6176.32080078125\n",
      "iter: 74 loss: 6138.83349609375\n",
      "iter: 75 loss: 6465.9033203125\n",
      "iter: 76 loss: 6294.69091796875\n",
      "iter: 77 loss: 6485.5302734375\n",
      "iter: 78 loss: 6448.19873046875\n",
      "iter: 79 loss: 5879.91552734375\n",
      "iter: 80 loss: 6335.111328125\n",
      "iter: 81 loss: 5883.2509765625\n",
      "iter: 82 loss: 6284.69091796875\n",
      "iter: 83 loss: 5716.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16440\\3951932543.py:94: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      4\u001B[0m usetime \u001B[38;5;241m=\u001B[39m end \u001B[38;5;241m-\u001B[39m start\n",
      "Cell \u001B[1;32mIn [4], line 63\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(iteration1, iteration2, pic, source, target)\u001B[0m\n\u001B[0;32m     60\u001B[0m content_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean((pic_f[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv5_2\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m neo_pic_f[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv5_2\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     62\u001B[0m patch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 63\u001B[0m patch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mcliploss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_patch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneo_pic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m norm_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     66\u001B[0m norm_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cliploss\u001B[38;5;241m.\u001B[39mforward_prior(pic, source, neo_pic, target)\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:326\u001B[0m, in \u001B[0;36mCLIPLoss.forward_patch\u001B[1;34m(self, src_img, source_class, target_img, target_class)\u001B[0m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_patch\u001B[39m(\u001B[38;5;28mself\u001B[39m, src_img: torch\u001B[38;5;241m.\u001B[39mTensor, source_class: \u001B[38;5;28mstr\u001B[39m, target_img: torch\u001B[38;5;241m.\u001B[39mTensor, target_class: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    324\u001B[0m \n\u001B[0;32m    325\u001B[0m     \u001B[38;5;66;03m# dir_loss = 1 * self.clip_directional_loss(src_img, source_class, target_img, target_class)\u001B[39;00m\n\u001B[1;32m--> 326\u001B[0m     patch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_directional_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_img\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_img\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_class\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;66;03m# dir_loss = 1 * self.global_clip_loss(target_img, f\"a {target_class}\")\u001B[39;00m\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;66;03m# dir_loss += 1 * self.clip_angle_loss(src_img, source_class, target_img, target_class)\u001B[39;00m\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;66;03m# print(loss1.item(),loss2.item(),loss3.item(),loss4.item())\u001B[39;00m\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;66;03m# loss += loss1 + loss2 + loss3 + loss4\u001B[39;00m\n\u001B[0;32m    331\u001B[0m     \u001B[38;5;66;03m# loss.requires_grad = True\u001B[39;00m\n\u001B[0;32m    333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m patch_loss\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:285\u001B[0m, in \u001B[0;36mCLIPLoss.patch_directional_loss\u001B[1;34m(self, src_img, source_class, target_img, target_class)\u001B[0m\n\u001B[0;32m    282\u001B[0m edit_direction \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m edit_direction\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mnorm(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    284\u001B[0m dirs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdirection_loss(edit_direction, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_direction)\n\u001B[1;32m--> 285\u001B[0m \u001B[43mdirs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdirs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m#     avg = dirs.mean()\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m#     delta = ((dirs-avg)**2).mean()\u001B[39;00m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dirs\u001B[38;5;241m.\u001B[39mmean()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n",
    "\n",
    "\n",
    "\n",
    "# 186.4968602657318\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open(file = \"neo.txt\", mode = \"w\") as file:\n",
    "#     for i in loss_li:\n",
    "#         file.write(str(i)+\" \")\n",
    "#     file.write(\"\\n\")\n",
    "#     file.write(str(cur_times+1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(100)]\n",
    "loss_li = [x/(cur_times+1) for x in loss_li]\n",
    "plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}