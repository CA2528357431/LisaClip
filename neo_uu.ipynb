{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork_uu import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = Unet(device).to(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "# vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "# for x in vgg.parameters():\n",
    "#     x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lr1 = 0.001\n",
    "lr2 = 0.0003\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 150\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loss_li = [0]*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_29996\\3599116407.py:4: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
      "E:\\Anaconda\\envs\\sth\\lib\\site-packages\\torchvision\\transforms\\transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pil = Image.open(f\"./source_pic/people0.jpg\")\n",
    "# pil = Image.open(f\"resulto.jpg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False\n",
    "# pic[:,1,:,:] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "path = \"result/result.jpg\"\n",
    "# path = \"0.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "big11 = torch.nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
    "big22 = torch.nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "\n",
    "list_selected = [4,9,14,19,39,59,79,99]\n",
    "\n",
    "# hot\n",
    "# hot_list = []\n",
    "\n",
    "# box\n",
    "patch_centers = []\n",
    "patch_sizes = []\n",
    "pic_patched = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# source = \"photo\"\n",
    "# source = \"cat\"\n",
    "# source = \"CG picture\"\n",
    "source = \"unhappy\"\n",
    "# source = \"man\"\n",
    "# source = \"flower\"\n",
    "# source = \"blue sky\"\n",
    "# source = \"brown hair\"\n",
    "\n",
    "# target = \"man with thick black moustache\"\n",
    "# target = \"black sky\"\n",
    "# target = \"sketch with pencil\"\n",
    "# target = \"dark black hair\"\n",
    "# target = \"gold boat\"\n",
    "# target = \"comic art\"\n",
    "# target = \"Barack Obama\"\n",
    "# target = \"joker\"\n",
    "# target = \"Mark Elliot Zuckerberg\"\n",
    "# target = \"Mona Lisa by Leonardo da Vinci\"\n",
    "# target = \"angry\"\n",
    "target = \"very happy\"\n",
    "# target = \"girl\"\n",
    "# target = \"Neon Light\"\n",
    "# target = \"shining gold car\"\n",
    "# target = \"pop art\"\n",
    "# target = \"old man\"\n",
    "# target = \"Watercolor Art with Thick Brush\"\n",
    "# target = \"Pixar\"\n",
    "# target = \"watercolor painting with thick brush\"\n",
    "# target = \"wheat field by Van Gogh\"\n",
    "# target = \"starry night by Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Monet\"\n",
    "# target = \"the girl with a pearl earring by Vermeer\"\n",
    "# target = \"painting by Paul Gauguin\"\n",
    "# target = \"oil painting by Raffaello Santi\"\n",
    "# target = \"poster in 1940s\"\n",
    "# target = \"oil painting by renoir\"\n",
    "# target = \"Barbizon School\"\n",
    "# target = \"steampunk\"\n",
    "# target = \"oil painting with thick brush\"\n",
    "# target = \"woman Wearing Raybon Sunglasses\"\n",
    "# target = \"the great wave off kanagawa\"\n",
    "# target = \"mosaic\"\n",
    "# target = \"fire\"\n",
    "# target = \"Chinese Brush Painting of mountains in black and white\"\n",
    "# target = \"snowy\"\n",
    "# target = \"sketch with pencil\"\n",
    "# target = \"pop art of night city\"\n",
    "# target = \"cubism\"\n",
    "# target = \"Cartoon\"\n",
    "# target = \"anime\"\n",
    "# target = \"white marble carving\"\n",
    "# target = \"Self-portrait by Pablo Picasso \"\n",
    "# target = \"David Hockney\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dli = []\n",
    "nli = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# patch.eps\n",
    "# patch_file = open(f\"./data/nums.txt\", mode=\"w\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "\n",
    "\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        neo_pic = model(input)\n",
    "        pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "        pil.save(f\"mid.jpg\")\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        # gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "        # patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.forward_prior(pic, source, neo_pic, target)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "        patch_loss_fast,patch_loss_slow, li = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        patch_loss_fast *= patch_lambda\n",
    "        patch_loss_slow *= patch_lambda\n",
    "\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_slow.backward(retain_graph=True)\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.deconv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_fast.backward(retain_graph=True)\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.deconv3.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        loss.backward()\n",
    "        # (loss+patch_loss_fast+patch_loss_slow).backward()\n",
    "\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_li[i]+=(loss+patch_loss_fast+patch_loss_slow).item()\n",
    "            print(\"iter:\", i + 1, \"fast_loss:\", patch_loss_fast.item(), \"slow_loss:\", patch_loss_slow.item())\n",
    "            print(\"iter:\", i + 1, \"loss:\", (loss+patch_loss_fast+patch_loss_slow).item())\n",
    "\n",
    "\n",
    "            # patch.eps\n",
    "\n",
    "            # for x in li:\n",
    "            #     patch_file.write(str(x)+\" \")\n",
    "            #\n",
    "            # patch_file.write(\"\\n\")\n",
    "\n",
    "            if (i+1)%10==0  or i==0:\n",
    "                neo_pic = model(input)\n",
    "                pil = topil(neo_pic.squeeze(0).cpu())\n",
    "                pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "                pil.save(f\"mid/{i//10}.jpg\")\n",
    "\n",
    "            # show loss\n",
    "\n",
    "            # dli.append(dir_loss.item()*dir_lambda)\n",
    "            # nli.append(norm_loss.item()*norm_lambda)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if i in list_selected:\n",
    "\n",
    "                # hot\n",
    "\n",
    "                # a1 = model.res[0].block[0].spatialattention.hot.detach()\n",
    "                # a2 = model.res[2].block[0].spatialattention.hot.detach()\n",
    "                # a3 = model.res2[0].block[0].spatialattention.hot.detach()\n",
    "                # a4 = model.res2[2].block[0].spatialattention.hot.detach()\n",
    "                #\n",
    "                # hot1 = big11(a1)[0,0,:,:]\n",
    "                # hot2 = big11(a2)[0,0,:,:]\n",
    "                # hot3 = big22(a3)[0,0,:,:]\n",
    "                # hot4 = big22(a4)[0,0,:,:]\n",
    "                #\n",
    "                # hot = hot1+hot2+hot3+hot4\n",
    "                #\n",
    "                # hot = hot.cpu().numpy()\n",
    "                #\n",
    "                # hot_list.append(hot)\n",
    "\n",
    "\n",
    "                # box\n",
    "                patch_centers.append(cliploss.patch_points.tolist())\n",
    "                patch_sizes.append(cliploss.patch_size)\n",
    "\n",
    "                pic_patched.append(model(input))\n",
    "\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.04537791758775711\n",
      "iter: 2 loss: 0.022188326343894005\n",
      "iter: 3 loss: 0.012859868817031384\n",
      "iter: 4 loss: 0.00797811895608902\n",
      "iter: 5 loss: 0.005427561234682798\n",
      "iter: 6 loss: 0.0039007775485515594\n",
      "iter: 7 loss: 0.002926961984485388\n",
      "iter: 8 loss: 0.002283369190990925\n",
      "iter: 9 loss: 0.001848921412602067\n",
      "iter: 10 loss: 0.001539385411888361\n",
      "iter: 11 loss: 0.0013066524406895041\n",
      "iter: 12 loss: 0.0011257764417678118\n",
      "iter: 13 loss: 0.0009918028954416513\n",
      "iter: 14 loss: 0.0009054010733962059\n",
      "iter: 15 loss: 0.0008487081504426897\n",
      "iter: 16 loss: 0.0008043148554861546\n",
      "iter: 17 loss: 0.0007690989878028631\n",
      "iter: 18 loss: 0.0007501982618123293\n",
      "iter: 19 loss: 0.000747989397495985\n",
      "iter: 20 loss: 0.000748860533349216\n",
      "iter: 21 loss: 0.0007403648342005908\n",
      "iter: 22 loss: 0.0007229816983453929\n",
      "iter: 23 loss: 0.0007002974743954837\n",
      "iter: 24 loss: 0.0006697738426737487\n",
      "iter: 25 loss: 0.0006320439861156046\n",
      "iter: 26 loss: 0.000596296158619225\n",
      "iter: 27 loss: 0.000568876916076988\n",
      "iter: 28 loss: 0.0005475543439388275\n",
      "iter: 29 loss: 0.000528565957210958\n",
      "iter: 30 loss: 0.0005110777565278113\n",
      "iter: 31 loss: 0.0004945240216329694\n",
      "iter: 32 loss: 0.00047645135782659054\n",
      "iter: 33 loss: 0.0004556608619168401\n",
      "iter: 34 loss: 0.0004353337862994522\n",
      "iter: 35 loss: 0.00041880420758388937\n",
      "iter: 36 loss: 0.00040523576899431646\n",
      "iter: 37 loss: 0.00039197609294205904\n",
      "iter: 38 loss: 0.0003785035223700106\n",
      "iter: 39 loss: 0.0003654026077128947\n",
      "iter: 40 loss: 0.0003522231709212065\n",
      "iter: 41 loss: 0.000339223857736215\n",
      "iter: 42 loss: 0.0003278519434388727\n",
      "iter: 43 loss: 0.0003178755287081003\n",
      "iter: 44 loss: 0.0003078838053625077\n",
      "iter: 45 loss: 0.00029802086646668613\n",
      "iter: 46 loss: 0.00028919504256919026\n",
      "iter: 47 loss: 0.00028097728500142694\n",
      "iter: 48 loss: 0.0002727267565205693\n",
      "iter: 49 loss: 0.00026497954968363047\n",
      "iter: 50 loss: 0.0002581867156550288\n",
      "iter: 51 loss: 0.0002519757836125791\n",
      "iter: 52 loss: 0.0002460977411828935\n",
      "iter: 53 loss: 0.00024059959105215967\n",
      "iter: 54 loss: 0.00023529931786470115\n",
      "iter: 55 loss: 0.00023024785332381725\n",
      "iter: 56 loss: 0.0002257820888189599\n",
      "iter: 57 loss: 0.00022177559731062502\n",
      "iter: 58 loss: 0.0002179350412916392\n",
      "iter: 59 loss: 0.0002143016754416749\n",
      "iter: 60 loss: 0.00021083297906443477\n",
      "iter: 61 loss: 0.0002074843505397439\n",
      "iter: 62 loss: 0.0002045056753559038\n",
      "iter: 63 loss: 0.000201809496502392\n",
      "iter: 64 loss: 0.00019903836073353887\n",
      "iter: 65 loss: 0.0001962885435204953\n",
      "iter: 66 loss: 0.00019368842185940593\n",
      "iter: 67 loss: 0.0001910991850309074\n",
      "iter: 68 loss: 0.00018862675642594695\n",
      "iter: 69 loss: 0.00018627542885951698\n",
      "iter: 70 loss: 0.00018386164447292686\n",
      "iter: 71 loss: 0.00018151439144276083\n",
      "iter: 72 loss: 0.00017930869944393635\n",
      "iter: 73 loss: 0.00017710571410134435\n",
      "iter: 74 loss: 0.00017495958309154958\n",
      "iter: 75 loss: 0.00017286364163737744\n",
      "iter: 76 loss: 0.00017080505494959652\n",
      "iter: 77 loss: 0.00016893532301764935\n",
      "iter: 78 loss: 0.0001671572681516409\n",
      "iter: 79 loss: 0.00016538912313990295\n",
      "iter: 80 loss: 0.0001636875094845891\n",
      "iter: 81 loss: 0.00016200606478378177\n",
      "iter: 82 loss: 0.00016037658497225493\n",
      "iter: 83 loss: 0.0001587874721735716\n",
      "iter: 84 loss: 0.00015718379290774465\n",
      "iter: 85 loss: 0.00015564149362035096\n",
      "iter: 86 loss: 0.000154151173774153\n",
      "iter: 87 loss: 0.00015270417497958988\n",
      "iter: 88 loss: 0.00015128384984564036\n",
      "iter: 89 loss: 0.00014983999426476657\n",
      "iter: 90 loss: 0.00014843382814433426\n",
      "iter: 91 loss: 0.0001470709394197911\n",
      "iter: 92 loss: 0.00014573990483768284\n",
      "iter: 93 loss: 0.0001444242661818862\n",
      "iter: 94 loss: 0.00014310856931842864\n",
      "iter: 95 loss: 0.00014183252642396837\n",
      "iter: 96 loss: 0.00014058308443054557\n",
      "iter: 97 loss: 0.0001393514685332775\n",
      "iter: 98 loss: 0.00013813021359965205\n",
      "iter: 99 loss: 0.000136921793455258\n",
      "iter: 100 loss: 0.00013574400509241968\n",
      "iter: 1 fast_loss: 4571.54833984375 slow_loss: 4998.779296875\n",
      "iter: 1 loss: 10100.02734375\n",
      "iter: 2 fast_loss: 4167.25146484375 slow_loss: 5128.830078125\n",
      "iter: 2 loss: 9803.03125\n",
      "iter: 3 fast_loss: 3967.094482421875 slow_loss: 5170.578125\n",
      "iter: 3 loss: 9634.37109375\n",
      "iter: 4 fast_loss: 4283.70654296875 slow_loss: 4659.64501953125\n",
      "iter: 4 loss: 9430.0498046875\n",
      "iter: 5 fast_loss: 3782.24951171875 slow_loss: 4963.142578125\n",
      "iter: 5 loss: 9222.5908203125\n",
      "iter: 6 fast_loss: 4208.31298828125 slow_loss: 4322.36474609375\n",
      "iter: 6 loss: 9001.126953125\n",
      "iter: 7 fast_loss: 3489.60107421875 slow_loss: 4861.244140625\n",
      "iter: 7 loss: 8812.044921875\n",
      "iter: 8 fast_loss: 3800.651611328125 slow_loss: 4391.44140625\n",
      "iter: 8 loss: 8641.29296875\n",
      "iter: 9 fast_loss: 4090.896484375 slow_loss: 3934.34130859375\n",
      "iter: 9 loss: 8461.439453125\n",
      "iter: 10 fast_loss: 3671.4248046875 slow_loss: 4243.94970703125\n",
      "iter: 10 loss: 8341.078125\n",
      "iter: 11 fast_loss: 4189.0869140625 slow_loss: 3603.515625\n",
      "iter: 11 loss: 8210.3076171875\n",
      "iter: 12 fast_loss: 3783.279296875 slow_loss: 3898.361328125\n",
      "iter: 12 loss: 8091.84716796875\n",
      "iter: 13 fast_loss: 3870.62060546875 slow_loss: 3753.410400390625\n",
      "iter: 13 loss: 8028.2392578125\n",
      "iter: 14 fast_loss: 3239.936767578125 slow_loss: 4283.70654296875\n",
      "iter: 14 loss: 7920.853515625\n",
      "iter: 15 fast_loss: 3875.63330078125 slow_loss: 3541.64892578125\n",
      "iter: 15 loss: 7807.99365234375\n",
      "iter: 16 fast_loss: 3137.6953125 slow_loss: 4159.1494140625\n",
      "iter: 16 loss: 7683.30712890625\n",
      "iter: 17 fast_loss: 3307.77734375 slow_loss: 3868.904052734375\n",
      "iter: 17 loss: 7558.6455078125\n",
      "iter: 18 fast_loss: 3043.281494140625 slow_loss: 4030.059814453125\n",
      "iter: 18 loss: 7449.556640625\n",
      "iter: 19 fast_loss: 3119.97998046875 slow_loss: 3893.623291015625\n",
      "iter: 19 loss: 7385.8212890625\n",
      "iter: 20 fast_loss: 2976.74560546875 slow_loss: 3724.5712890625\n",
      "iter: 20 loss: 7068.287109375\n",
      "iter: 21 fast_loss: 3233.0703125 slow_loss: 3564.582763671875\n",
      "iter: 21 loss: 7160.12548828125\n",
      "iter: 22 fast_loss: 1705.558837890625 slow_loss: 3597.67919921875\n",
      "iter: 22 loss: 5662.21240234375\n",
      "iter: 23 fast_loss: 996.734619140625 slow_loss: 4065.422119140625\n",
      "iter: 23 loss: 5418.3828125\n",
      "iter: 24 fast_loss: 401.6876220703125 slow_loss: 3423.408447265625\n",
      "iter: 24 loss: 4177.07373046875\n",
      "iter: 25 fast_loss: 103.82080078125 slow_loss: 3362.640380859375\n",
      "iter: 25 loss: 3813.18994140625\n",
      "iter: 26 fast_loss: 195.89996337890625 slow_loss: 3421.48583984375\n",
      "iter: 26 loss: 3957.615478515625\n",
      "iter: 27 fast_loss: 288.665771484375 slow_loss: 3187.47705078125\n",
      "iter: 27 loss: 3811.62255859375\n",
      "iter: 28 fast_loss: 98.876953125 slow_loss: 3045.6162109375\n",
      "iter: 28 loss: 3475.722412109375\n",
      "iter: 29 fast_loss: 279.876708984375 slow_loss: 3544.73876953125\n",
      "iter: 29 loss: 4151.09375\n",
      "iter: 30 fast_loss: 98.1903076171875 slow_loss: 2690.345703125\n",
      "iter: 30 loss: 3110.013671875\n",
      "iter: 31 fast_loss: 95.306396484375 slow_loss: 2998.237548828125\n",
      "iter: 31 loss: 3410.270751953125\n",
      "iter: 32 fast_loss: 93.93310546875 slow_loss: 3148.13232421875\n",
      "iter: 32 loss: 3554.041748046875\n",
      "iter: 33 fast_loss: 266.693115234375 slow_loss: 3033.943115234375\n",
      "iter: 33 loss: 3608.111572265625\n",
      "iter: 34 fast_loss: 181.20574951171875 slow_loss: 2857.337890625\n",
      "iter: 34 loss: 3342.018310546875\n",
      "iter: 35 fast_loss: 177.978515625 slow_loss: 3174.224853515625\n",
      "iter: 35 loss: 3651.927734375\n",
      "iter: 36 fast_loss: 179.62646484375 slow_loss: 2895.515380859375\n",
      "iter: 36 loss: 3374.115234375\n",
      "iter: 37 fast_loss: 93.2464599609375 slow_loss: 2761.962890625\n",
      "iter: 37 loss: 3146.93212890625\n",
      "iter: 38 fast_loss: 89.53857421875 slow_loss: 2811.676025390625\n",
      "iter: 38 loss: 3188.9365234375\n",
      "iter: 39 fast_loss: 90.4998779296875 slow_loss: 2879.241943359375\n",
      "iter: 39 loss: 3257.963134765625\n",
      "iter: 40 fast_loss: 257.080078125 slow_loss: 2881.233154296875\n",
      "iter: 40 loss: 3418.284423828125\n",
      "iter: 41 fast_loss: 91.461181640625 slow_loss: 2895.103515625\n",
      "iter: 41 loss: 3262.78515625\n",
      "iter: 42 fast_loss: 256.9427490234375 slow_loss: 2829.3916015625\n",
      "iter: 42 loss: 3362.554443359375\n",
      "iter: 43 fast_loss: 90.29388427734375 slow_loss: 2742.118896484375\n",
      "iter: 43 loss: 3106.134033203125\n",
      "iter: 44 fast_loss: 254.1961669921875 slow_loss: 2789.97802734375\n",
      "iter: 44 loss: 3313.646728515625\n",
      "iter: 45 fast_loss: 89.05792236328125 slow_loss: 2689.79638671875\n",
      "iter: 45 loss: 3044.828125\n",
      "iter: 46 fast_loss: 170.2880859375 slow_loss: 2630.195556640625\n",
      "iter: 46 loss: 3063.208251953125\n",
      "iter: 47 fast_loss: 89.53857421875 slow_loss: 2887.8935546875\n",
      "iter: 47 loss: 3239.905029296875\n",
      "iter: 48 fast_loss: 90.98052978515625 slow_loss: 2719.25341796875\n",
      "iter: 48 loss: 3068.706298828125\n",
      "iter: 49 fast_loss: 252.2735595703125 slow_loss: 2878.898681640625\n",
      "iter: 49 loss: 3386.76953125\n",
      "iter: 50 fast_loss: 90.087890625 slow_loss: 2769.79052734375\n",
      "iter: 50 loss: 3114.973876953125\n",
      "iter: 51 fast_loss: 88.50860595703125 slow_loss: 2846.489013671875\n",
      "iter: 51 loss: 3188.091796875\n",
      "iter: 52 fast_loss: 88.92059326171875 slow_loss: 2444.938720703125\n",
      "iter: 52 loss: 2783.578125\n",
      "iter: 53 fast_loss: 86.7919921875 slow_loss: 2657.661376953125\n",
      "iter: 53 loss: 2994.6708984375\n",
      "iter: 54 fast_loss: 91.461181640625 slow_loss: 2701.606689453125\n",
      "iter: 54 loss: 3040.660888671875\n",
      "iter: 55 fast_loss: 248.1536865234375 slow_loss: 2734.016357421875\n",
      "iter: 55 loss: 3226.76318359375\n",
      "iter: 56 fast_loss: 89.813232421875 slow_loss: 2748.91650390625\n",
      "iter: 56 loss: 3083.323486328125\n",
      "iter: 57 fast_loss: 91.5985107421875 slow_loss: 2812.5\n",
      "iter: 57 loss: 3145.069580078125\n",
      "iter: 58 fast_loss: 88.43994140625 slow_loss: 2583.709716796875\n",
      "iter: 58 loss: 2911.6201171875\n",
      "iter: 59 fast_loss: 90.2252197265625 slow_loss: 2782.150390625\n",
      "iter: 59 loss: 3109.8466796875\n",
      "iter: 60 fast_loss: 252.2735595703125 slow_loss: 2448.71533203125\n",
      "iter: 60 loss: 2942.2109375\n",
      "iter: 61 fast_loss: 87.890625 slow_loss: 2634.521484375\n",
      "iter: 61 loss: 2957.0087890625\n",
      "iter: 62 fast_loss: 88.64593505859375 slow_loss: 2748.161376953125\n",
      "iter: 62 loss: 3073.403564453125\n",
      "iter: 63 fast_loss: 89.6759033203125 slow_loss: 2856.857421875\n",
      "iter: 63 loss: 3182.12890625\n",
      "iter: 64 fast_loss: 168.15948486328125 slow_loss: 2844.841064453125\n",
      "iter: 64 loss: 3252.720458984375\n",
      "iter: 65 fast_loss: 168.5028076171875 slow_loss: 2657.93603515625\n",
      "iter: 65 loss: 3063.031982421875\n",
      "iter: 66 fast_loss: 92.6971435546875 slow_loss: 2801.239013671875\n",
      "iter: 66 loss: 3134.90234375\n",
      "iter: 67 fast_loss: 175.84991455078125 slow_loss: 2421.38671875\n",
      "iter: 67 loss: 2830.57763671875\n",
      "iter: 68 fast_loss: 92.010498046875 slow_loss: 2890.64013671875\n",
      "iter: 68 loss: 3212.615478515625\n",
      "iter: 69 fast_loss: 90.2252197265625 slow_loss: 2597.442626953125\n",
      "iter: 69 loss: 2915.630615234375\n",
      "iter: 70 fast_loss: 89.60723876953125 slow_loss: 2582.954345703125\n",
      "iter: 70 loss: 2899.7744140625\n",
      "iter: 71 fast_loss: 89.263916015625 slow_loss: 3226.478515625\n",
      "iter: 71 loss: 3546.20654296875\n",
      "iter: 72 fast_loss: 261.95526123046875 slow_loss: 2507.904052734375\n",
      "iter: 72 loss: 3003.698974609375\n",
      "iter: 73 fast_loss: 176.12457275390625 slow_loss: 2691.10107421875\n",
      "iter: 73 loss: 3099.3154296875\n",
      "iter: 74 fast_loss: 93.45245361328125 slow_loss: 2371.5361328125\n",
      "iter: 74 loss: 2695.95263671875\n",
      "iter: 75 fast_loss: 87.7532958984375 slow_loss: 2656.768798828125\n",
      "iter: 75 loss: 2973.23388671875\n",
      "iter: 76 fast_loss: 88.5772705078125 slow_loss: 2904.510498046875\n",
      "iter: 76 loss: 3220.548583984375\n",
      "iter: 77 fast_loss: 96.13037109375 slow_loss: 2990.959228515625\n",
      "iter: 77 loss: 3314.801513671875\n",
      "iter: 78 fast_loss: 181.9610595703125 slow_loss: 2666.24462890625\n",
      "iter: 78 loss: 3078.66796875\n",
      "iter: 79 fast_loss: 260.16998291015625 slow_loss: 2858.09326171875\n",
      "iter: 79 loss: 3348.725341796875\n",
      "iter: 80 fast_loss: 92.28515625 slow_loss: 2965.00390625\n",
      "iter: 80 loss: 3286.7509765625\n",
      "iter: 81 fast_loss: 255.9814453125 slow_loss: 2728.111328125\n",
      "iter: 81 loss: 3212.554443359375\n",
      "iter: 82 fast_loss: 91.461181640625 slow_loss: 2624.6337890625\n",
      "iter: 82 loss: 2942.431640625\n",
      "iter: 83 fast_loss: 91.3238525390625 slow_loss: 2723.85400390625\n",
      "iter: 83 loss: 3039.51416015625\n",
      "iter: 84 fast_loss: 94.6197509765625 slow_loss: 2661.43798828125\n",
      "iter: 84 loss: 2979.392333984375\n",
      "iter: 85 fast_loss: 103.546142578125 slow_loss: 2756.67578125\n",
      "iter: 85 loss: 3084.304443359375\n",
      "iter: 86 fast_loss: 99.5635986328125 slow_loss: 2860.49658203125\n",
      "iter: 86 loss: 3187.76708984375\n",
      "iter: 87 fast_loss: 92.83447265625 slow_loss: 3233.894287109375\n",
      "iter: 87 loss: 3551.06005859375\n",
      "iter: 88 fast_loss: 92.35382080078125 slow_loss: 3132.75146484375\n",
      "iter: 88 loss: 3448.18701171875\n",
      "iter: 89 fast_loss: 92.010498046875 slow_loss: 2844.085693359375\n",
      "iter: 89 loss: 3159.67822265625\n",
      "iter: 90 fast_loss: 94.482421875 slow_loss: 2944.748046875\n",
      "iter: 90 loss: 3260.81103515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_29996\\1047062930.py:28: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_29996\\1047062930.py:128: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# patch.eps\n",
    "# patch_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_uu = open(\"neo_uu.txt\", \"r\")\n",
    "# read_loss_li = file_uu.readline()\n",
    "# read_loss_li = [float(x) for x in read_loss_li.split()]\n",
    "# if not read_loss_li:\n",
    "#     read_loss_li = [0]*100\n",
    "# cur_times = int(file_uu.readline())\n",
    "# file_uu.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# x = [i for i in range(100)]\n",
    "# plt.plot(x,loss_li[:100],color=\"red\",marker=\"o\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     loss_li[i]+=read_loss_li[i]\n",
    "# with open(file = \"neo_uu.txt\", mode = \"w\") as file:\n",
    "#     for i in loss_li:\n",
    "#         file.write(str(i)+\" \")\n",
    "#     file.write(\"\\n\")\n",
    "#     file.write(str(cur_times+1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x = [i for i in range(100)]\n",
    "# plt.plot(x,gli,color=\"red\",marker=\"o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show loss\n",
    "\n",
    "# x = [i for i in range(100)]\n",
    "# plt.plot(x,dli,color=\"red\",marker=\"o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show loss\n",
    "\n",
    "# x = [i for i in range(100)]\n",
    "# plt.plot(x,nli,color=\"red\",marker=\"o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show loss\n",
    "\n",
    "# x = [i for i in range(100)]\n",
    "# li = [dli[i]+nli[i] for i in range(100)]\n",
    "# plt.plot(x,li,color=\"red\",marker=\"o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show loss\n",
    "\n",
    "# x = [i for i in range(100)]\n",
    "# li = [x/64 for x in cliploss.right_patch]\n",
    "# plt.plot(x,li,color=\"red\",marker=\"o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show loss\n",
    "\n",
    "# print(sum(cliploss.right_patch)/6400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show hot\n",
    "\n",
    "# i = 0\n",
    "# for hot in hot_list:\n",
    "#     fig,_ = plt.subplots()\n",
    "#     plt.imshow(hot)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     fig.savefig(f'./hot/{i}.eps',dpi=600,format='eps')\n",
    "#     i+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# box\n",
    "\n",
    "# for j in range(8):\n",
    "#     pic = pic_patched[j]\n",
    "#     size = patch_sizes[j]\n",
    "#     points = patch_centers[j]\n",
    "#\n",
    "#     hsize = size//2\n",
    "#\n",
    "#     for y,x in points:\n",
    "#         for i in range(-hsize, hsize+1):\n",
    "#             pic[0][0][y+i][x+hsize] = 1\n",
    "#             pic[0][0][y+i][x-hsize] = 1\n",
    "#             pic[0][0][y+hsize][x+i] = 1\n",
    "#             pic[0][0][y-hsize][x+i] = 1\n",
    "#\n",
    "#             pic[0][1][y+i][x+hsize] = 0\n",
    "#             pic[0][1][y+i][x-hsize] = 0\n",
    "#             pic[0][1][y+hsize][x+i] = 0\n",
    "#             pic[0][1][y-hsize][x+i] = 0\n",
    "#\n",
    "#             pic[0][2][y+i][x+hsize] = 0\n",
    "#             pic[0][2][y+i][x-hsize] = 0\n",
    "#             pic[0][2][y+hsize][x+i] = 0\n",
    "#             pic[0][2][y-hsize][x+i] = 0\n",
    "#\n",
    "#     pil = topil(pic.squeeze(0).cpu())\n",
    "#     pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "#\n",
    "#     pil.save(f\"box/{list_selected[j]+1}.jpg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hotbox\n",
    "\n",
    "# for j in range(8):\n",
    "#     pic = torch.zeros(1,3,512,512)\n",
    "#     size = patch_sizes[j]\n",
    "#     points = patch_centers[j]\n",
    "#\n",
    "#     hsize = size//2\n",
    "#\n",
    "#     for y,x in points:\n",
    "#         pic[0,0,y-hsize:y+hsize+1,x-hsize:x+hsize+1] +=1\n",
    "#\n",
    "#\n",
    "#     pic = pic[0,0].numpy()\n",
    "#     fig,_ = plt.subplots()\n",
    "#     plt.imshow(pic)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     fig.savefig(f'./hotbox/{list_selected[j]+1}.jpg')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}